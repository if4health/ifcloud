# -*- coding: utf-8 -*-
"""CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EnF-g53sESBilO4bvAjmmRyGmE1HJ4S_

## **Modelo com filtro**
"""

import numpy as np
import pandas as pd
import pywt
import statistics
import keras
from keras import layers
import tensorflow as tf
from keras.layers import Lambda
from keras.models import Model
from keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense
from keras.regularizers import l2
from keras.optimizers import Adam
from sklearn.model_selection import KFold
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import tempfile
import requests

#Functions

#Filtro Bandpass
def band_filter(signal):
  for cont_sin in range(len(signal)):

    #Band pass Filter
    # Initialize result
    result = None

    # Create a copy of the input signal
    sig = signal.copy()

    # Apply the low pass filter using the equation given
    for index in range(len(signal)):
      sig[index] = signal[index]

      if (index >= 1):
        sig[index] += 2*sig[index-1]

      if (index >= 2):
        sig[index] -= sig[index-2]

      if (index >= 6):
        sig[index] -= 2*signal[index-6]

      if (index >= 12):
        sig[index] += signal[index-12]

    # Copy the result of the low pass filter
    result = sig.copy()

    # Apply the high pass filter using the equation given
    for index in range(len(signal)):
      result[index] = -1*sig[index]

      if (index >= 1):
        result[index] -= result[index-1]

      if (index >= 16):
        result[index] += 32*sig[index-16]

      if (index >= 32):
        result[index] += sig[index-32]

    passado = result

    for index in range(len(signal)):
      if (index >=1):
        result[index] = passado[index] - passado[index-1] + 0.995*result[index-1]
      else:
        result[index]=0

    # Normalize the result from the high pass filter
    media = np.mean(result)
    desvio = np.std(result)
    result = (result-media)/desvio

    return result

#Dataset para vetores Numpy
def adeq_dts(DF_MLII):
  colunas = ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37", "38", "39", "40", "41", "42", "43", "44", "45", "46", "47", "48", "49", "50", "51", "52", "53", "54", "55", "56", "57", "58", "59", "60", "61", "62", "63", "64", "65", "66", "67", "68", "69", "70", "71", "72", "73", "74", "75", "76", "77", "78", "79", "80", "81", "82", "83", "84", "85", "86", "87", "88", "89", "90", "91", "92", "93", "94", "95", "96", "97", "98", "99", "100", "101", "102", "103", "104", "105", "106", "107", "108", "109", "110", "111", "112", "113", "114", "115", "116", "117", "118", "119", "120", "121", "122", "123", "124", "125", "126", "127", "128", "129", "130", "131", "132", "133", "134", "135", "136", "137", "138", "139", "140", "141", "142", "143", "144", "145", "146", "147", "148", "149", "150", "151", "152", "153", "154", "155", "156", "157", "158", "159", "160", "161", "162", "163", "164", "165", "166", "167", "168", "169", "170", "171", "172", "173", "174", "175", "176", "177", "178", "179", "180", "181", "182", "183", "184", "185", "186", "187", "188", "189", "190", "191", "192", "193", "194", "195", "196", "197", "198", "199", "200", "201", "202", "203", "204", "205", "206", "207", "208", "209", "210", "211", "212", "213", "214", "215", "216", "217", "218", "219", "220", "221", "222", "223", "224", "225", "226", "227", "228", "229", "230", "231", "232", "233", "234", "235", "236", "237", "238", "239", "240", "241", "242", "243", "244", "245", "246", "247", "248", "249", "250", "251", "252", "253", "254", "255", "256", "257", "258", "259"]

  #Convertendo para string colunas DF_MLII
  colunas_mlii = DF_MLII.columns
  colunas_mlii_str = []
  for index in range(len(colunas_mlii)):
    colunas_mlii_str.append(str(colunas_mlii[index]))

  #inserindo novas colunas
  DF_MLII.columns = colunas_mlii_str

  #Adequando sequência dos dados
  DF_MLII = DF_MLII[colunas]

  #Adequando para tensor
  base_MLII = []
  for index in range(len(DF_MLII)):
      base_MLII.append(DF_MLII.iloc[index].values)

  return base_MLII

#Traduzindo predição realizada
def tpSig_predc(predc):
  carac_predic = []
  for index in range(len(predc)):
    temp_vet = predc[index].tolist()
    temp_var = -1
    temp_var = temp_vet.index(max(temp_vet))
    if(temp_var == 0):
      carac_predic.append("N")
    elif(temp_var == 1):
      carac_predic.append("S")
    elif(temp_var == 2):
      carac_predic.append("V")
    elif(temp_var == 3):
      carac_predic.append("F")
    elif(temp_var == 4):
      carac_predic.append("Q")
    else: print("ERRO")
  return carac_predic

#Importando dados sinal MIT para DF
df = pd.read_csv("uploads_src/200.csv",sep=",")
df.columns = (["Temp","MLII","V5"])

#Importando dados annotations MIT para DF
r_peak = []
tp_sig = []

annotations_txt = open("uploads_src/200annotations.txt", "r")
for index in annotations_txt:
  r_peak.append(index[15:21])
  tp_sig.append(index[26])
annotations_txt.close()

del r_peak[0]
del r_peak[1]
del tp_sig[0]
del tp_sig[1]

for index in range(len(r_peak)):
  r_peak[index] = int(r_peak[index])

#Realizando a filtragem do sinal
mlii = df["MLII"].values
pos = df["Temp"].values

mlii_filter = band_filter(mlii)


##Adequando posições dos picos R
for index in range(len(r_peak)):
  if(r_peak[index]+20 < len(mlii_filter)):
    r_peak[index] = r_peak[index]+20
  else:
    r_peak.pop(index)

df["MLII"] = mlii_filter
df["Temp"] = pos

#Dividir por batida (Segmentação)
pnts_ant = 130
pnts_post = 130

bat_mlii = []
loc_r_peak = []
for index in range(len(r_peak)):
  sig_aux_mlii = []

  if((r_peak[index]-1-pnts_ant >= 0) and (r_peak[index]+pnts_post < len(df["MLII"]))):
    sig_aux_mlii = df["MLII"][(r_peak[index]-1-pnts_ant):(r_peak[index]+pnts_post)].values

    bat_mlii.append(sig_aux_mlii)
    loc_r_peak.append(r_peak[index])

#Transformando em dataset
df_mlii = pd.DataFrame(bat_mlii)

#Consolidar dataset
#Convertendo Dataset para matriz de vetores numpy
base_MLII = adeq_dts(df_mlii)
base_MLII = np.asarray(base_MLII)

#Predição e manipulação do resultado final
#Criando novo modelo
def criar_modelo():
    reg = l2(0.02)
    inputs = Input(shape=(260,))
    #inputs_expanded = tf.expand_dims(inputs, axis=-1)
    inputs_expanded = Lambda(lambda x: tf.expand_dims(x, axis=-1))(inputs)
    conv1 = Conv1D(filters=5, kernel_size=3, padding='valid', activation='relu', kernel_regularizer=reg)(inputs_expanded)
    pool1 = MaxPooling1D(pool_size=2, strides=2)(conv1)
    conv2 = Conv1D(filters=10, kernel_size=4, padding='valid', activation='relu', kernel_regularizer=reg)(pool1)
    pool2 = MaxPooling1D(pool_size=2, strides=2)(conv2)
    conv3 = Conv1D(filters=20, kernel_size=4, padding='valid', activation='relu', kernel_regularizer=reg)(pool2)
    pool3 = MaxPooling1D(pool_size=2, strides=2)(conv3)
    flatten = Flatten()(pool3)
    dense1 = Dense(30, activation='relu', kernel_regularizer=reg)(flatten)
    dense2 = Dense(20, activation='relu', kernel_regularizer=reg)(dense1)
    outputs = Dense(5, activation='softmax')(dense2)
    modelo = Model(inputs=inputs, outputs=outputs)
    optimizer = Adam(learning_rate=0.003)
    modelo.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
    return modelo

# Carregar o modelo criado
model = criar_modelo()

url = "https://andredelmestre.com.br/download/modelo_CNN.h5"

# Baixar o arquivo de pesos
response = requests.get(url)
response.raise_for_status()  # Verifica se o download foi bem-sucedido

# Salvar os pesos em um arquivo temporário e carregá-los no modelo
with tempfile.NamedTemporaryFile(suffix=".h5") as temp_file:
    temp_file.write(response.content)
    temp_file.flush()  # Garante que o conteúdo seja gravado no disco
    model.load_weights(temp_file.name)
#Aplicar a classificação da batida através do modelo carregado
predic = model.predict([base_MLII])

#Transformar a predição em um vetor de saída
#Identificando batida através de predição
vetor_final_predic = tpSig_predc(predic)

print(vetor_final_predic)
